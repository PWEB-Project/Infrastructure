---
## Provide custom recording or alerting rules to be deployed into the cluster.
##
# additionalPrometheusRulesMap: {}
#  rule-name:
#    groups:
#    - name: my_group
#      rules:
#      - record: my_record
#        expr: 100 * my_record

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:

  ## Settings affecting alertmanagerSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#alertmanagerspec
  ##
  alertmanagerSpec:
    
    ## Storage is the definition of how storage will be used by the Alertmanager instances.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    # storage: {}
      # volumeClaimTemplate:
      #   spec:
      #     storageClassName: standard-rwo
      #     resources:
      #       requests:
      #         storage: 50Gi

    ## Define resources requests and limits for single Pods.
    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/
    ##
    resources:
      requests:
        cpu: "50m"
        memory: "256M"
      limits:
        cpu: "250m"
        memory: "512M"
    # requests:
    #   memory: 400Mi

## Using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
##
grafana:
  adminUser: admin
  adminPassword: admin

  image:
    tag: 8.3.4

  env:
    GF_INSTALL_PLUGINS: "flant-statusmap-panel,grafana-piechart-panel"
    GF_SERVER_ROOT_URL: "%(protocol)s://%(domain)s:%(http_port)s/grafana/"
    GF_SERVER_SERVE_FROM_SUB_PATH: true

  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      folder: /tmp/dashboards
      provider: 
        foldersFromFilesStructure: true

    ## Annotations for Grafana dashboard configmaps
    ##
    annotations: 
      k8s-sidecar-target-directory: "/tmp/dashboards/kubernetes"

  ## Configure additional grafana datasources (passed through tpl)
  ## ref: http://docs.grafana.org/administration/provisioning/#datasources
  # additionalDataSources: []
  # - name: prometheus-sample
  #   access: proxy
  #   basicAuth: true
  #   basicAuthPassword: pass
  #   basicAuthUser: daco
  #   editable: false
  #   jsonData:
  #       tlsSkipVerify: true
  #   orgId: 1
  #   type: prometheus
  #   url: https://{{ printf "%s-prometheus.svc" .Release.Name }}:9090
  #   version: 1

  # resources:
  #   requests:
  #     cpu: "100m"
  #     memory: "256Mi"
  #   limits:
  #     cpu: "500m"
  #     memory: "512Mi"

## Deploy a Prometheus instance
##
prometheus:
  ## Settings affecting prometheusSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheusspec
  ##
  prometheusSpec:

    additionalScrapeConfigsSecret:
        enabled: true
        name: prometheus-additional-configs
        key: additional-configs.yaml

    ## How long to retain metrics
    ##
    retention: 10d

    ## Number of replicas of each shard to deploy for a Prometheus deployment.
    ## Number of replicas multiplied by shards is the total number of Pods created.
    ##
    replicas: 1

    ## Resource limits & requests
    ##
    resources:
      requests:
        cpu: 300m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 2G

    ## Prometheus StorageSpec for persistent data
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    storageSpec:
    ## Using PersistentVolumeClaim
    ##
      volumeClaimTemplate:
        spec:
          storageClassName: standard-rwo
          resources:
            requests:
              storage: 50Gi
